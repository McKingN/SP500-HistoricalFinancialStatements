{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone --branch master https://github.com/McKingN/SP500-HistoricalFinancialStatements.git","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T17:09:15.929585Z","iopub.execute_input":"2024-12-01T17:09:15.930009Z","iopub.status.idle":"2024-12-01T17:09:18.274201Z","shell.execute_reply.started":"2024-12-01T17:09:15.929970Z","shell.execute_reply":"2024-12-01T17:09:18.272973Z"}},"outputs":[{"name":"stdout","text":"Cloning into 'SP500-HistoricalFinancialStatements'...\nremote: Enumerating objects: 103, done.\u001b[K\nremote: Counting objects: 100% (103/103), done.\u001b[K\nremote: Compressing objects: 100% (30/30), done.\u001b[K\nremote: Total 103 (delta 68), reused 100 (delta 67), pack-reused 0 (from 0)\u001b[K\nReceiving objects: 100% (103/103), 342.58 KiB | 3.17 MiB/s, done.\nResolving deltas: 100% (68/68), done.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"%cd SP500-HistoricalFinancialStatements","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T17:09:20.404695Z","iopub.execute_input":"2024-12-01T17:09:20.405093Z","iopub.status.idle":"2024-12-01T17:09:20.413087Z","shell.execute_reply.started":"2024-12-01T17:09:20.405057Z","shell.execute_reply":"2024-12-01T17:09:20.411828Z"}},"outputs":[{"name":"stdout","text":"/kaggle/working/SP500-HistoricalFinancialStatements\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!cd data/SP500_components_statements;ls","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T17:09:21.797089Z","iopub.execute_input":"2024-12-01T17:09:21.797489Z","iopub.status.idle":"2024-12-01T17:09:22.883486Z","shell.execute_reply.started":"2024-12-01T17:09:21.797454Z","shell.execute_reply":"2024-12-01T17:09:22.881889Z"}},"outputs":[{"name":"stdout","text":"ABBV.json  ACN.json   AES.json\tAMD.json  MMM.json\nABT.json   ADBE.json  AFL.json\tAOS.json\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"!pip install -r requirements.txt","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T17:09:24.576395Z","iopub.execute_input":"2024-12-01T17:09:24.576826Z","iopub.status.idle":"2024-12-01T17:09:36.375795Z","shell.execute_reply.started":"2024-12-01T17:09:24.576788Z","shell.execute_reply":"2024-12-01T17:09:36.374450Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (2.2.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 2)) (2.32.3)\nRequirement already satisfied: numpy>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 1)) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 1)) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 1)) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->-r requirements.txt (line 1)) (2024.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->-r requirements.txt (line 2)) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->-r requirements.txt (line 2)) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->-r requirements.txt (line 2)) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->-r requirements.txt (line 2)) (2024.8.30)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 1)) (1.16.0)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"\nfrom collections import defaultdict\nimport os\nimport json\nimport pandas as pd\nimport requests\n\n\ndef verify_and_find_next_json(directory):\n    \"\"\"\n    Vérifie les fichiers JSON dans un dossier et détermine le prochain nom de fichier JSON.\n\n    :param directory: Chemin vers le dossier contenant les fichiers JSON.\n    :return: Une chaîne correspondant au prochain fichier JSON (\"i.json\" ou \"j.json\").\n    \"\"\"\n    # Liste des fichiers dans le dossier\n    files = os.listdir(directory)\n    \n    # Filtrer les fichiers qui ont un nom correspondant à \"N.json\" avec N un entier\n    json_files = [f for f in files if f.endswith('.json') and f[:-5].isdigit()]\n    \n    if not json_files:\n        # Si le dossier est vide ou aucun fichier JSON valide trouvé\n        return \"1.json\"\n    \n    # Extraire les entiers des noms de fichiers (par exemple, \"1.json\" -> 1)\n    json_indices = sorted(int(f[:-5]) for f in json_files)\n    \n    # Vérifier s'il manque un numéro dans la séquence de 1 à max\n    for i in range(1, max(json_indices) + 1):\n        if i not in json_indices:\n            return f\"{i}.json\"\n    \n    # Si tous les fichiers de 1 à max existent, retourner \"max + 1\"\n    if max(json_indices) == 54 :\n        print(\"Le dossier est complet. Merci pour votre aide\")\n        return\n    return f\"{max(json_indices) + 1}.json\"\n\ndef split_json(input_file, output_folder, chunk_size=8):\n    \"\"\"\n    Divise un fichier JSON en plusieurs fichiers avec un nombre limité d'éléments.\n\n    :param input_file: Chemin vers le fichier JSON source.\n    :param output_folder: Dossier où enregistrer les fichiers divisés.\n    :param chunk_size: Nombre maximal d'éléments par fichier.\n    \"\"\"\n    # Vérifie si le dossier de sortie existe, sinon le crée\n    os.makedirs(output_folder, exist_ok=True)\n    \n    # Charge les données du fichier JSON\n    with open(input_file, 'r', encoding='utf-8') as f:\n        data = json.load(f)\n    \n    # Obtenir toutes les clés et les diviser en groupes\n    keys = list(data.keys())\n    chunks = [keys[i:i + chunk_size] for i in range(0, len(keys), chunk_size)]\n    \n    # Crée un fichier pour chaque groupe\n    for i, chunk in enumerate(chunks, start=1):\n        chunk_data = {key: data[key] for key in chunk}\n        output_file = os.path.join(output_folder, f\"{i}.json\")\n        \n        # Enregistre le groupe dans un fichier JSON\n        with open(output_file, 'w', encoding='utf-8') as f:\n            json.dump(chunk_data, f, indent=4)\n        \n        print(f\"Fichier créé : {output_file}\")\n\ndef fetch_financial_data(ticker, api_key, output_folder):\n    \"\"\"\n    Récupère les données financières (état des résultats, bilan, et flux de trésorerie)\n    pour un ticker donné via l'API Alpha Vantage. Les données sont sauvegardées dans\n    un fichier JSON nommé \"ticker.json\" avant d'être retournées sous forme de dictionnaire.\n\n    :param ticker: Le symbole boursier du titre.\n    :param api_key: Clé API pour accéder à l'API Alpha Vantage.\n    :param output_folder: Chemin vers le dossier où sauvegarder les données JSON.\n    :return: Un dictionnaire contenant les données financières.\n    \"\"\"\n    base_url = \"https://www.alphavantage.co/query\"\n    functions = [\"INCOME_STATEMENT\", \"BALANCE_SHEET\", \"CASH_FLOW\"]\n    financial_data = {}\n\n    # Vérifie si le dossier de sortie existe, sinon le crée\n    os.makedirs(output_folder, exist_ok=True)\n\n    for func in functions:\n        params = {\n            \"function\": func,\n            \"symbol\": ticker,\n            \"apikey\": api_key\n        }\n        response = requests.get(base_url, params=params)\n        if response.status_code == 200:\n            financial_data[func.lower()] = response.json()\n        else:\n            print(f\"Échec de la récupération de {func} pour {ticker}: {response.status_code}\")\n            financial_data[func.lower()] = None\n\n    # Chemin du fichier de sortie\n    output_file = os.path.join(output_folder, f\"{ticker}.json\")\n    \n    # Sauvegarde des données financières dans un fichier JSON\n    with open(output_file, 'w', encoding='utf-8') as f:\n        json.dump(financial_data, f, indent=4)\n    \n    print(f\"Données sauvegardées dans {output_file}\")\n\n    return financial_data\n\n\ndef process_financial_data(financial_data, ticker):\n    \"\"\"\n    Process raw financial data to merge income statement, balance sheet, and cash flow.\n    Returns a dictionary of financial data aggregated by fiscal year.\n    \"\"\"\n    # Extract reports from the raw financial data\n    income_reports = financial_data.get(\"income_statement\", {}).get(\"annualReports\", [])\n    balance_reports = financial_data.get(\"balance_sheet\", {}).get(\"annualReports\", [])\n    cashflow_reports = financial_data.get(\"cash_flow\", {}).get(\"annualReports\", [])\n\n    # Convert lists to DataFrames\n    income_df = pd.DataFrame(income_reports)\n    balance_df = pd.DataFrame(balance_reports)\n    cashflow_df = pd.DataFrame(cashflow_reports)\n\n    # Merge data on fiscalDateEnding\n    combined_df = income_df.merge(balance_df, on=\"fiscalDateEnding\", suffixes=('_income', '_balance'))\n    combined_df = combined_df.merge(cashflow_df, on=\"fiscalDateEnding\", suffixes=('', '_cashflow'))\n\n    # Convert numeric fields to floats\n    for col in combined_df.columns:\n        if col != \"fiscalDateEnding\":\n            combined_df[col] = pd.to_numeric(combined_df[col], errors=\"coerce\")\n\n    # Create a dictionary with fiscalDateEnding as keys\n    combined_data = combined_df.set_index(\"fiscalDateEnding\").to_dict(orient=\"index\")\n\n    # Add the ticker to each entry\n    for date in combined_data:\n        combined_data[date][\"ticker\"] = ticker\n\n    return combined_data\n\n\ndef aggregate_financial_data(input_json_path, api_key, output_json_path, outDir):\n    \"\"\"\n    Aggregate financial data for tickers listed in the input JSON file.\n    Outputs a JSON file with combined financial data for all tickers by fiscal year.\n    \"\"\"\n    # Load tickers from input JSON file\n    with open(input_json_path, \"r\") as file:\n        tickers_data = json.load(file)\n\n    aggregated_data = defaultdict(dict)\n\n    for ticker, details in tickers_data.items():\n        print(f\"Processing {ticker}...\")\n        financial_data = fetch_financial_data(ticker, api_key, outDir)\n        if all(financial_data.values()):  # Check if all API calls were successful\n            processed_data = process_financial_data(financial_data, ticker)\n            for date, data in processed_data.items():\n                aggregated_data[date][ticker] = data\n        else:\n            print(f\"Skipping {ticker} due to missing data.\")\n\n    # Save aggregated data to JSON\n    with open(output_json_path, \"w\") as output_file:\n        json.dump(aggregated_data, output_file, indent=4)\n\n    print(f\"Aggregated financial data saved to {output_json_path}\")\n\ndef main(api, components_dir=\"data/FilteredSP500_components_splitted\", results_dir=\"data/SP500_components_CombinedStatements\", saveStockStatementsDir=\"data/SP500_components_statements\"):\n    inputFileName = verify_and_find_next_json(results_dir)\n    inputFilePath = os.path.join(components_dir, inputFileName)\n    outputFilePath = os.path.join(results_dir, inputFileName)\n    aggregate_financial_data(input_json_path=inputFilePath, api_key=api, output_json_path=outputFilePath, outDir=saveStockStatementsDir)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T17:10:58.011131Z","iopub.execute_input":"2024-12-01T17:10:58.011589Z","iopub.status.idle":"2024-12-01T17:10:58.037166Z","shell.execute_reply.started":"2024-12-01T17:10:58.011550Z","shell.execute_reply":"2024-12-01T17:10:58.036103Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"if __name__ == '__main__' :\n    #API_KEY = \"GSUGWUPW6P8KYJIF\"\n    API_KEY=\"REW2AY5M6LJAOAU4\"\n    main(API_KEY)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T17:10:59.844616Z","iopub.execute_input":"2024-12-01T17:10:59.845027Z","iopub.status.idle":"2024-12-01T17:11:10.757919Z","shell.execute_reply.started":"2024-12-01T17:10:59.844990Z","shell.execute_reply":"2024-12-01T17:11:10.756245Z"}},"outputs":[{"name":"stdout","text":"Processing AFL...\nDonnées sauvegardées dans data/SP500_components_statements/AFL.json\nProcessing A...\nDonnées sauvegardées dans data/SP500_components_statements/A.json\nProcessing APD...\nDonnées sauvegardées dans data/SP500_components_statements/APD.json\nProcessing AKAM...\nDonnées sauvegardées dans data/SP500_components_statements/AKAM.json\nProcessing ALB...\nDonnées sauvegardées dans data/SP500_components_statements/ALB.json\nProcessing ARE...\nDonnées sauvegardées dans data/SP500_components_statements/ARE.json\nProcessing ALGN...\nDonnées sauvegardées dans data/SP500_components_statements/ALGN.json\nProcessing ALLE...\nDonnées sauvegardées dans data/SP500_components_statements/ALLE.json\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_30/3825787011.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m#API_KEY = \"GSUGWUPW6P8KYJIF\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mAPI_KEY\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"REW2AY5M6LJAOAU4\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAPI_KEY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_30/4141385291.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(api, components_dir, results_dir, saveStockStatementsDir)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcomponents_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"data/FilteredSP500_components_splitted\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"data/SP500_components_CombinedStatements\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaveStockStatementsDir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"data/SP500_components_statements\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0minputFileName\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mverify_and_find_next_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0minputFilePath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomponents_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputFileName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0moutputFilePath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputFileName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m     \u001b[0maggregate_financial_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_json_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputFilePath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_json_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutputFilePath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutDir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msaveStockStatementsDir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/tmp/ipykernel_30/4141385291.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(input_json_path, api_key, output_json_path, outDir)\u001b[0m\n\u001b[1;32m    157\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mticker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetails\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtickers_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Processing {ticker}...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0mfinancial_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_financial_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mticker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapi_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutDir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinancial_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Check if all API calls were successful\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m             \u001b[0mprocessed_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_financial_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinancial_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mticker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprocessed_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0maggregated_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mticker\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_30/4141385291.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(financial_data, ticker)\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0mcashflow_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcashflow_reports\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;31m# Merge data on fiscalDateEnding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0mcombined_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mincome_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbalance_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"fiscalDateEnding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffixes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_income'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_balance'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m     \u001b[0mcombined_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombined_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcashflow_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"fiscalDateEnding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffixes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_cashflow'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;31m# Convert numeric fields to floats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcol\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcombined_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m  10828\u001b[0m         \u001b[0mvalidate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mMergeValidate\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10829\u001b[0m     ) -> DataFrame:\n\u001b[1;32m  10830\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmerge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m> 10832\u001b[0;31m         return merge(\n\u001b[0m\u001b[1;32m  10833\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10834\u001b[0m             \u001b[0mright\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10835\u001b[0m             \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    166\u001b[0m             \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         )\n\u001b[1;32m    169\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         op = _MergeOperation(\n\u001b[0m\u001b[1;32m    171\u001b[0m             \u001b[0mleft_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mright_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m             \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[1;32m    790\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m             \u001b[0mleft_drop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m             \u001b[0mright_drop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 794\u001b[0;31m         ) = self._get_merge_keys()\n\u001b[0m\u001b[1;32m    795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mleft_drop\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_labels_or_levels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft_drop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1293\u001b[0m                         \u001b[0;31m# Then we're either Hashable or a wrong-length arraylike,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m                         \u001b[0;31m#  the latter of which will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m                         \u001b[0mrk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHashable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1296\u001b[0m                         \u001b[0;32mif\u001b[0m \u001b[0mrk\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1297\u001b[0;31m                             \u001b[0mright_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1298\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1299\u001b[0m                             \u001b[0;31m# work-around for merge_asof(right_index=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1300\u001b[0m                             \u001b[0mright_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mright\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1907\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mother_axes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1908\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_level_reference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1909\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1910\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1911\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1913\u001b[0m         \u001b[0;31m# Check for duplicates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1914\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'fiscalDateEnding'"],"ename":"KeyError","evalue":"'fiscalDateEnding'","output_type":"error"}],"execution_count":8},{"cell_type":"code","source":"!cd data/SP500_components_statements;ls","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T17:11:15.829116Z","iopub.execute_input":"2024-12-01T17:11:15.829531Z","iopub.status.idle":"2024-12-01T17:11:16.912195Z","shell.execute_reply.started":"2024-12-01T17:11:15.829497Z","shell.execute_reply":"2024-12-01T17:11:16.910844Z"}},"outputs":[{"name":"stdout","text":"A.json\t   ACN.json   AFL.json\t ALGN.json  AOS.json  MMM.json\nABBV.json  ADBE.json  AKAM.json  ALLE.json  APD.json\nABT.json   AES.json   ALB.json\t AMD.json   ARE.json\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"!cd data/SP500_components_statements;ls","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T15:16:10.441792Z","iopub.execute_input":"2024-12-01T15:16:10.442197Z","iopub.status.idle":"2024-12-01T15:16:11.615507Z","shell.execute_reply.started":"2024-12-01T15:16:10.442166Z","shell.execute_reply":"2024-12-01T15:16:11.614016Z"}},"outputs":[{"name":"stdout","text":"A.json\t   ABT.json  ADBE.json\tAFL.json  AOS.json  MMM.json\nABBV.json  ACN.json  AES.json\tAMD.json  APD.json\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}